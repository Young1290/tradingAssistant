import os
import ccxt
import pandas as pd
import ta
import json
import re
import feedparser
import requests
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from pydantic import BaseModel
from dotenv import load_dotenv
from datetime import datetime

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = FastAPI()

@app.get("/")
def read_root():
    return {"message": "Trading Assistant API - See /docs for endpoints"}

# 2. å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. åˆå§‹åŒ–
exchange = ccxt.binance()
GENAI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GENAI_API_KEY:
    print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° GEMINI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
else:
    genai.configure(api_key=GENAI_API_KEY)

model = genai.GenerativeModel('gemini-2.5-flash')

class AnalysisRequest(BaseModel):
    symbol: str 

# --- è¾…åŠ©åŠŸèƒ½ ---
def get_fear_and_greed():
    try:
        url = "https://api.alternative.me/fng/?limit=1"
        r = requests.get(url, timeout=5)
        return {"value": r.json()['data'][0]['value'], "value_classification": r.json()['data'][0]['value_classification']}
    except:
        return {"value": "50", "value_classification": "Neutral"}

def get_crypto_news(symbol_query: str):
    """è·å– Google News (åŒ…å«å‘å¸ƒæ—¶é—´)"""
    try:
        # ç®€å•æ˜ å°„
        query_map = {'BTC': 'Bitcoin', 'ETH': 'Ethereum', 'SOL': 'Solana'}
        query = query_map.get(symbol_query.split('/')[0], symbol_query)
        
        # RSS URL
        rss_url = f"https://news.google.com/rss/search?q={query}+crypto&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(rss_url)
        
        news_items = []
        for entry in feed.entries[:5]:
            # è·å–å‘å¸ƒæ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤º 'æœªçŸ¥'
            pub_date = entry.get('published', 'N/A')
            
            # å°è¯•ç®€å•æ ¼å¼åŒ–æ—¥æœŸ (å»æ‰æ—¶åŒºç­‰å†—ä½™ä¿¡æ¯ï¼Œè®©å‰ç«¯æ˜¾ç¤ºæ›´çŸ­)
            # Google æ ¼å¼é€šå¸¸æ˜¯: "Fri, 05 Dec 2025 03:00:00 GMT"
            try:
                # æˆªå–å‰16ä¸ªå­—ç¬¦ -> "Fri, 05 Dec 2025" 
                # æˆ–è€…ä¿ç•™åŸæ ·è®©å‰ç«¯å¤„ç†
                pass 
            except:
                pass

            news_items.append({
                "title": entry.title,
                "link": entry.link,
                "published": pub_date  # <--- æ–°å¢è¿™è¡Œ
            })
            
        return news_items
    except Exception as e:
        print(f"è·å–æ–°é—»å‡ºé”™: {e}")
        return []

def fetch_data(symbol: str, timeframe='1h', limit=500):
    try:
        bars = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)
        df = pd.DataFrame(bars, columns=['time', 'open', 'high', 'low', 'close', 'volume'])
        df['time'] = pd.to_datetime(df['time'], unit='ms')
        return df
    except Exception as e:
        print(f"Error fetching {timeframe}: {e}")
        return pd.DataFrame()

# --- ğŸ”¥ æ ¸å¿ƒæŒ‡æ ‡è®¡ç®— ---

def calculate_indicators(df):
    """å¾®è§‚æŒ‡æ ‡ (1H/15m): RSI, MACD, EMA, ADX"""
    if df.empty: return df
    df['RSI'] = ta.momentum.RSIIndicator(close=df['close'], window=14).rsi()
    macd = ta.trend.MACD(close=df['close'])
    df['MACD'] = macd.macd()
    df['MACD_signal'] = macd.macd_signal()
    df['MACD_diff'] = macd.macd_diff() # æŸ±çŠ¶å›¾
    
    df['EMA20'] = ta.trend.EMAIndicator(close=df['close'], window=20).ema_indicator()
    df['EMA50'] = ta.trend.EMAIndicator(close=df['close'], window=50).ema_indicator()
    df['EMA200'] = ta.trend.EMAIndicator(close=df['close'], window=200).ema_indicator()
    
    df['BBL_20_2.0'] = ta.volatility.BollingerBands(close=df['close']).bollinger_lband()
    df['BBU_20_2.0'] = ta.volatility.BollingerBands(close=df['close']).bollinger_hband()
    df['ATR'] = ta.volatility.AverageTrueRange(high=df['high'], low=df['low'], close=df['close']).average_true_range()
    df['ADX'] = ta.trend.ADXIndicator(high=df['high'], low=df['low'], close=df['close']).adx()
    
    # Pivot Points
    prev_high = df['high'].shift(1)
    prev_low = df['low'].shift(1)
    prev_close = df['close'].shift(1)
    df['Pivot'] = (prev_high + prev_low + prev_close) / 3
    df['R1'] = (2 * df['Pivot']) - prev_low
    df['S1'] = (2 * df['Pivot']) - prev_high
    df['Vol_MA20'] = df['volume'].rolling(window=20).mean()
    return df.fillna(0)

def calculate_daily_indicators(df):
    """å®è§‚æŒ‡æ ‡ (1D): SMA200, æ–œç‡, ä¹–ç¦»ç‡"""
    if df.empty: return df
    df['SMA50'] = ta.trend.SMAIndicator(close=df['close'], window=50).sma_indicator()
    df['SMA200'] = ta.trend.SMAIndicator(close=df['close'], window=200).sma_indicator()
    
    df['SMA200_Slope'] = (df['SMA200'] - df['SMA200'].shift(5)) / df['SMA200'].shift(5) * 100
    df['SMA200_Dev'] = (df['close'] - df['SMA200']) / df['SMA200'] * 100
    return df.fillna(0)

# --- ğŸ”¥ è¿™é‡Œå°±æ˜¯ä½ ç¼ºå°‘çš„ Function ğŸ”¥ ---
def get_trend_status(row, is_macro=False, macro_bullish=False):
    """
    å‰ç«¯çº¢ç»¿ç¯çŠ¶æ€åˆ¤æ–­
    - is_macro: æ˜¯å¦æ˜¯å®è§‚å‘¨æœŸ (æ—¥çº¿)
    - macro_bullish: å¦‚æœæ˜¯å®è§‚ï¼Œæ˜¯ç‰›è¿˜æ˜¯ç†Š
    """
    # --- 1. å¦‚æœæ˜¯æ—¥çº¿ (Macro)ï¼Œç›´æ¥æ ¹æ®åŒå‘¨æœŸå…±æŒ¯é€»è¾‘å®šè‰² ---
    if is_macro:
        return "bullish" if macro_bullish else "bearish"

    # --- 2. å¦‚æœæ˜¯çŸ­çº¿ (Micro)ï¼Œçœ‹ ADX å’Œ EMA20 ---
    # å¦‚æœ ADX ä½ï¼Œè¯´æ˜æ²¡è¶‹åŠ¿ï¼Œç°è‰² (éœ‡è¡)
    if row['ADX'] < 20:
        return "neutral"

    # åŸºäº EMA æ’åˆ—åˆ¤æ–­
    is_uptrend = row['close'] > row['EMA20']
    is_downtrend = row['close'] < row['EMA20']
    
    # åŸºäº MACD åŠ¨èƒ½åˆ¤æ–­
    momentum_up = row['MACD_diff'] > 0
    
    # å¼ºè¶‹åŠ¿
    if is_uptrend and momentum_up:
        return "bullish"
    elif is_downtrend and not momentum_up:
        return "bearish"
    
    # å¼±è¶‹åŠ¿ (ç»™å‰ç«¯æµ…è‰²)
    if row['RSI'] > 55: return "weak_bullish"
    if row['RSI'] < 45: return "weak_bearish"
    
    return "neutral"

# --- API ---

@app.get("/api/market-data/{symbol}")
async def get_market_data(symbol: str):
    """å›¾è¡¨æ•°æ®"""
    try:
        formatted_symbol = symbol.replace('-', '/').upper()
        if '/' not in formatted_symbol: formatted_symbol = formatted_symbol[:-4] + '/' + formatted_symbol[-4:]
        
        # è¿”å›æ—¥çº¿æ•°æ®ç”»é•¿çº¿å›¾
        df = fetch_data(formatted_symbol, timeframe='1d', limit=365)
        df = calculate_daily_indicators(df)
        
        chart_data = []
        for index, row in df.iterrows():
            chart_data.append({
                "time": int(row['time'].timestamp()),
                "open": row['open'], "high": row['high'], "low": row['low'], "close": row['close'],
                "volume": row['volume'],
                "sma50": row['SMA50'], "sma200": row['SMA200']
            })
        return {"symbol": formatted_symbol, "data": chart_data}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analyze")
async def analyze_market(request: AnalysisRequest):
    try:
        # 1. åŒè„‘æ•°æ®è·å–
        df_daily = fetch_data(request.symbol, '1d', limit=500)
        df_hourly = fetch_data(request.symbol, '1h', limit=100)
        
        if df_daily.empty: df_daily = df_hourly # å…œåº•
        if df_hourly.empty: raise HTTPException(status_code=500, detail="æ•°æ®è·å–å¤±è´¥")

        # 2. è®¡ç®—æŒ‡æ ‡
        df_daily = calculate_daily_indicators(df_daily)
        df_hourly = calculate_indicators(df_hourly)
        
        last_daily = df_daily.iloc[-1]
        last_hourly = df_hourly.iloc[-1]
        
        # 3. å®è§‚èƒŒæ™¯åˆ¤å®š (ğŸ”¥ V6++ç­–ç•¥æ ¸å¿ƒé€»è¾‘)
        slope = last_daily['SMA200_Slope']
        dev = last_daily['SMA200_Dev']
        price = last_daily['close']
        sma200 = last_daily['SMA200']
        
        # ğŸ”¥ V6++é€»è¾‘: å®½æ¾ç‰›å¸‚åˆ¤å®š (ä»·æ ¼>SMA200 OR æ–œç‡>0)
        # ä¼˜åŠ¿: å‡å°‘è¯¯åˆ¤ï¼Œé¿å…éœ‡è¡å¸‚é¢‘ç¹æ­¢æŸï¼Œ5å¹´å›æµ‹+514% vs V7çš„-18%
        is_bull_regime = (price > sma200) or (slope > 0)
        
        # åšç©ºæ¡ä»¶åˆ¤å®š (V6++æ–°å¢)
        can_short = (not is_bull_regime) and (dev < -10) and (slope < -0.5)
        
        regime_desc = "ğŸ® ç‰›å¸‚/å¼ºåŠ¿èƒŒæ™¯" if is_bull_regime else "ğŸ» ç†Šå¸‚/å¼±åŠ¿èƒŒæ™¯"

        # 4. ç”Ÿæˆé›·è¾¾å›¾ä¿¡å·
        ui_signals = {}
        mtf_desc = {}
        target_timeframes = ['1w', '1d', '4h', '1h'] 

        for tf in target_timeframes:
            if tf == '1d':
                # æ—¥çº¿å¼ºåˆ¶è·Ÿéšä¸¥æ ¼é£æ§åˆ¤å®š
                status = "bullish" if is_bull_regime else "bearish"
                ui_signals[tf] = status
                mtf_desc[tf] = f"è¶‹åŠ¿:{'ç‰›å¸‚' if is_bull_regime else 'ç†Šå¸‚'} (SMA200:{sma200:.0f})"
            elif tf == '1w':
                df_w = fetch_data(request.symbol, '1w', limit=52)
                if not df_w.empty:
                    df_w = calculate_indicators(df_w)
                    ui_signals[tf] = get_trend_status(df_w.iloc[-1])
                    mtf_desc[tf] = f"RSI:{df_w.iloc[-1]['RSI']:.1f}"
                else: ui_signals[tf] = "neutral"
            elif tf == '1h':
                 ui_signals[tf] = get_trend_status(last_hourly)
                 mtf_desc[tf] = f"RSI:{last_hourly['RSI']:.1f}"
            else:
                df_tf = fetch_data(request.symbol, tf, limit=100)
                if not df_tf.empty:
                    df_tf = calculate_indicators(df_tf)
                    ui_signals[tf] = get_trend_status(df_tf.iloc[-1])
                    mtf_desc[tf] = f"RSI:{df_tf.iloc[-1]['RSI']:.1f}"
                else: ui_signals[tf] = "neutral"

        # 5. å¾®è§‚æ•°æ®
        momentum_4h = 0.0
        if len(df_hourly) >= 4:
            momentum_4h = (last_hourly['close'] - df_hourly.iloc[-4]['close']) / df_hourly.iloc[-4]['close'] * 100
            
        macd_status = "âœ… é‡‘å‰" if last_hourly['MACD'] > last_hourly['MACD_signal'] else "âš ï¸ æ­»å‰"
        
        # 6. Prompt (ğŸ”¥ V6++ç­–ç•¥ç‰ˆ - å†å²å›æµ‹+514%æ”¶ç›Š)
        news_list = get_crypto_news(request.symbol)
        news_text = "\n".join([f"- {n['title']}" for n in news_list])
        fng = get_fear_and_greed()
        
        # é¢„è®¡ç®—åšç©ºçŠ¶æ€ï¼ˆé¿å…f-stringåµŒå¥—ï¼‰
        short_status = "âœ…å¯åšç©º" if can_short else "âŒä¸å¯åšç©º"

        prompt = f"""
        ä½ æ˜¯ä¸€ä½é‡‡ç”¨**V6++ç­–ç•¥**çš„è¶‹åŠ¿äº¤æ˜“å‘˜ã€‚
        
        ã€å®è§‚èƒŒæ™¯ (æ—¥çº¿)ã€‘
        - ç¯å¢ƒ: **{regime_desc}**
        - SMA200: ${sma200:.2f}
        - ä¹–ç¦»ç‡: {dev:.2f}% (ä»·æ ¼è·ç¦»SMA200çš„è·ç¦»)
        - æ–œç‡: {slope:.4f}
        - ææ…ŒæŒ‡æ•°: {fng['value']}
        
        ã€å¾®è§‚å‚è€ƒ (1å°æ—¶)ã€‘
        - ç°ä»·: ${last_hourly['close']:.2f}
        - Pivot: ${last_hourly['Pivot']:.2f}
        - MACD: {macd_status}
        
        
        ã€ğŸ”¥ V6++æ ¸å¿ƒå†³ç­–é€»è¾‘ (å†å²å›æµ‹+514%æ”¶ç›Š) ğŸ”¥ã€‘
        
        **V6++ç‰›å¸‚åˆ¤å®š**: ä»·æ ¼>SMA200 OR æ–œç‡>0 (å®½æ¾åˆ¤å®šï¼Œé¿å…è¯¯åˆ¤)
        
        **åœºæ™¯ A: ç‰›å¸‚èƒŒæ™¯**
        *é€»è¾‘: æŒæœ‰ä¸ºä¸»ï¼Œå›è°ƒä¹°å…¥ï¼Œç›ˆåˆ©100%è·åˆ©äº†ç»“ã€‚*
        1. **ğŸ¯ 100%è·åˆ©äº†ç»“**: å¦‚æœæŒä»“ç›ˆåˆ© >= 100% -> **ç«‹å³å–å‡ºé”å®šåˆ©æ¶¦** (é¿å…é¡¶ç‚¹å›æ’¤)ã€‚
        2. **æ‚¬å´–å‹’é©¬**: ä¹–ç¦»ç‡ < 3% ä¸” æ–œç‡ < 0 (å‡çº¿æ‹å¤´) -> **å‡ä»“/è§‚æœ›**ã€‚
        3. **ç‰›å¸‚å›è°ƒ**: ä»·æ ¼ > SMA200 ä¸” RSI < 50 -> **ä¹°å…¥/åŠ ä»“**ã€‚
        4. **è¶‹åŠ¿è·Ÿéš**: ä»·æ ¼ç¨³åœ¨ SMA200 ä¹‹ä¸Šæˆ–æ–œç‡å‘ä¸Š -> **æŒæœ‰**ã€‚

        **åœºæ™¯ B: ç†Šå¸‚èƒŒæ™¯ (ä»·æ ¼<SMA200 ä¸” æ–œç‡<0)**
        *é€»è¾‘: å¯åšç©ºèµšé’±ï¼Œä¸è¦è½»æ˜“æŠ„åº•ã€‚*
        1. **æ­¢æŸ/ç©ºä»“**: ä»·æ ¼ < SMA200 -> **å–å‡º/è§‚æœ›**ã€‚
        2. **ğŸ“‰ åšç©ºæœºä¼š (å½“å‰{short_status})**: 
           - æ¡ä»¶: ä¹–ç¦»ç‡ < -10% ä¸” æ–œç‡ < -0.5% -> **å¯è€ƒè™‘åšç©º**
           - å¹³ç©º: ç›ˆåˆ©100% æˆ– ä¹–ç¦»ç‡>-5% æˆ– è½¬ç‰›
        3. **æç«¯è¶…è·Œ**: ä¹–ç¦»ç‡ < -30% -> å¯è½»ä»“åšåå¼¹ã€‚

        ã€ä»»åŠ¡ã€‘
        è¯·ç»™å‡ºæœªæ¥ **14-30å¤©** çš„æ“ä½œå»ºè®®ã€‚
        
        è¯·è¾“å‡ºçº¯ JSON:
        {{
            "direction": "ä¹°å…¥" | "æŒæœ‰" | "å–å‡º" | "è§‚æœ›" | "åšç©º",
            "entry_price": "å»ºè®®æŒ‚å•ä»·",
            "stop_loss": "å»ºè®®æ­¢æŸä»· (å‚è€ƒ SMA200)",
            "target_price": "å»ºè®®æ­¢ç›ˆä»· (å¤šå¤´è€ƒè™‘100%è·åˆ©)",
            "reasoning": "è¯¦ç»†ç†ç”± (å¿…é¡»åŸºäºV6++é€»è¾‘)",
            "confidence": "1-10",
            "risk_warning": "é£é™©æç¤º"
        }}
        """
        
        response = model.generate_content(prompt)
        
        try:
            cleaned_text = re.sub(r'```json\s*', '', response.text).replace('```', '').strip()
            analysis_json = json.loads(cleaned_text)
            
            
            return {
                "ui_signals": ui_signals,
                "analysis": analysis_json,
                "news": news_list,
                "fng": fng,
                "v6pp_info": {
                    "is_bull_v6": bool(is_bull_regime),
                    "can_short": bool(can_short),
                    "strategy_version": "V6++",
                    "backtest_performance": "+514% (2021-2025)"
                }
            }
        except json.JSONDecodeError:
            return {
                "ui_signals": ui_signals,
                "analysis": {"direction": "è§£æé”™è¯¯", "reasoning": response.text, "confidence": 0},
                "news": news_list,
                "fng": fng
            }

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- ğŸ”¥ æƒ…æ™¯åˆ†æ API (æ–°å¢) ---

from scenario_scoring import ScenarioScorer

@app.post("/api/scenario-analysis")
async def scenario_analysis(request: AnalysisRequest):
    """
    å®è§‚æƒ…æ™¯åˆ†æ - è‡ªåŠ¨è·å–æ•°æ®å¹¶è®¡ç®—å››å¤§æƒ…æ™¯æ¦‚ç‡
    """
    try:
        # 1. è‡ªåŠ¨è·å–å®è§‚æ•°æ®
        print(f"ğŸ“Š å¼€å§‹è·å– {request.symbol} çš„å®è§‚æ•°æ®...")
        
        # 1.1 ç¾å…ƒæŒ‡æ•°ï¼ˆç®€åŒ– - ä½¿ç”¨å›ºå®šå€¼æˆ–å¤–éƒ¨APIï¼‰
        dxy_value = "98.5 (ä¼°ç®—)"
        dxy_trend = "èµ°å¼±"
        
        # 1.2 Fed åˆ©ç‡æ”¿ç­–ï¼ˆé€šè¿‡AIåˆ†ææ–°é—»ï¼‰
        try:
            rss_url = "https://news.google.com/rss/search?q=Federal+Reserve+interest+rate&hl=en-US&gl=US&ceid=US:en"
            feed = feedparser.parse(rss_url)
            news_titles = [entry.title for entry in feed.entries[:5]]
            news_text = "\n".join([f"- {title}" for title in news_titles])
            
            prompt = f"""æ ¹æ®ä»¥ä¸‹æœ€æ–°æ–°é—»ï¼Œç”¨ä¸€å¥è¯æ€»ç»“å½“å‰ Fed åˆ©ç‡æ”¿ç­–çŠ¶æ€ï¼š
{news_text}
è¯·ç”¨ç®€çŸ­æ ¼å¼å›ç­”ï¼Œä¾‹å¦‚: "é™æ¯ 25bp" æˆ– "ç»´æŒåˆ©ç‡ä¸å˜" æˆ– "åŠ æ¯ 50bp"
"""
            response = model.generate_content(prompt)
            fed_policy = response.text.strip()
        except:
            fed_policy = "ç»´æŒç°çŠ¶"
        
        # 1.3 BTC ETF å‡€æµå…¥ (æ¥è‡ª Farside Investors çœŸå®æ•°æ®)
        try:
            from btc_etf_flow_helper import get_btc_etf_flow_summary
            etf_flow = get_btc_etf_flow_summary()
            print(f"âœ“ è·å–åˆ° BTC ETF çœŸå®æ•°æ®: {etf_flow}")
        except Exception as e:
            print(f"âš ï¸ BTC ETF æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨AIåˆ†ææ–°é—»
            try:
                rss_url = "https://news.google.com/rss/search?q=Bitcoin+ETF+flow&hl=en-US&gl=US&ceid=US:en"
                feed = feedparser.parse(rss_url)
                news_titles = [entry.title for entry in feed.entries[:5]]
                news_text = "\n".join([f"- {title}" for title in news_titles])
                
                prompt = f"""æ ¹æ®ä»¥ä¸‹æ–°é—»ï¼Œæ€»ç»“æœ€è¿‘çš„ BTC ETF èµ„é‡‘æµåŠ¨æƒ…å†µï¼š
{news_text}
è¯·ç”¨ç®€çŸ­æ ¼å¼å›ç­”ï¼Œä¾‹å¦‚: "å•å‘¨æµå…¥ $1.2B" æˆ– "å•æœˆæµå‡º $3B" æˆ– "æ¯æ—¥å°å¹…æ³¢åŠ¨"
"""
                response = model.generate_content(prompt)
                etf_flow = response.text.strip()
            except:
                etf_flow = "æ•°æ®ä¸æ˜ç¡®"
        
        # 1.4 é•¿æœŸæŒæœ‰è€…è¡Œä¸º (æ¥è‡ª CryptoQuant é“¾ä¸ŠçœŸå®æ•°æ®)
        try:
            from holder_behavior_helper import get_holder_behavior_summary as get_holder_summary
            holder_behavior = get_holder_summary()
            print(f"âœ“ è·å–åˆ°æŒæœ‰è€…è¡Œä¸ºé“¾ä¸Šæ•°æ®: {holder_behavior}")
        except Exception as e:
            print(f"âš ï¸ æŒæœ‰è€…è¡Œä¸ºæ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆå·²åœ¨ holder_behavior_helper.py ä¸­å®ç°
            holder_behavior = "æ•°æ®ä¸å¯ç”¨"
        
        # 1.5 æŒ–çŸ¿æˆæœ¬ (æ¥è‡ª Bitdeer çŸ¿æœºå…³æœºä»·æ•°æ®)
        try:
            from mining_shutdown_price import get_mining_cost_summary
            mining_cost = get_mining_cost_summary()
            print(f"âœ“ è·å–åˆ°çŸ¿æœºå…³æœºä»·æ•°æ®: {mining_cost}")
        except Exception as e:
            print(f"âš ï¸ çŸ¿æœºæˆæœ¬æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å€¼: {e}")
            mining_cost = "çº¦$75,000 (å‚è€ƒå€¼)"
        
        # 1.6 ç¾è‚¡ S&P500 è¡¨ç° (ä» Yahoo Finance è·å–çœŸå®æ•°æ®)
        try:
            from sp500_helper import get_sp500_performance
            sp500_performance = get_sp500_performance()
            print(f"âœ“ è·å–åˆ° S&P500 çœŸå®æ•°æ®: {sp500_performance}")
        except Exception as e:
            print(f"âš ï¸ S&P500 æ•°æ®è·å–å¤±è´¥: {e}")
            sp500_performance = "æ•°æ®ä¸å¯ç”¨"
        
        # 1.7 é£é™©äº‹ä»¶
        try:
            rss_url = "https://news.google.com/rss/search?q=cryptocurrency+crisis+OR+exchange+collapse+OR+regulation&hl=en-US&gl=US&ceid=US:en"
            feed = feedparser.parse(rss_url)
            news_titles = [entry.title for entry in feed.entries[:5]]
            news_text = "\n".join([f"- {title}" for title in news_titles])
            
            prompt = f"""æ ¹æ®ä»¥ä¸‹æ–°é—»ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨é‡å¤§é£é™©äº‹ä»¶æˆ–é»‘å¤©é¹…ï¼š
{news_text}
è¯·ç”¨ç®€çŸ­æ ¼å¼å›ç­”ï¼Œä¾‹å¦‚: "æ— æ˜æ˜¾é£é™©" æˆ– "æŸäº¤æ˜“æ‰€çˆ†é›·" æˆ– "ç›‘ç®¡æ”¶ç´§"
"""
            response = model.generate_content(prompt)
            risk_events = response.text.strip()
        except:
            risk_events = "æœªæ£€æµ‹åˆ°"
        
        # 2. æ±‡æ€»å®è§‚æ•°æ®
        macro_data = {
            "ç¾å…ƒæŒ‡æ•° (DXY)": f"{dxy_value}, {dxy_trend}",
            "Fed åˆ©ç‡æ”¿ç­–": fed_policy,
            "BTC ETF å‡€æµå…¥": etf_flow,
            "é•¿æœŸæŒæœ‰è€…è¡Œä¸º": holder_behavior,
            "æŒ–çŸ¿ç”Ÿäº§æˆæœ¬": mining_cost,
            "ç¾è‚¡è¡¨ç° (S&P500)": sp500_performance,
            "é£é™©äº‹ä»¶": risk_events
        }
        
        # 3. ä½¿ç”¨è§„åˆ™è¯„åˆ†ç³»ç»Ÿè®¡ç®—æ¦‚ç‡
        scorer = ScenarioScorer()
        probabilities = scorer.calculate_scenario_scores(macro_data)
        most_likely = scorer.get_most_likely_scenario(probabilities)
        
        # 4. ç”¨ AI ç”Ÿæˆè¯¦ç»†åˆ†æå’Œæ“ä½œå»ºè®®
        scenario_names = {
            "scenario_1": "æƒ…æ™¯ 1: Vå‹åè½¬",
            "scenario_2": "æƒ…æ™¯ 2: é«˜ä½æ¨ªç›˜",
            "scenario_3": "æƒ…æ™¯ 3: ç¼“æ…¢ç†Šå¸‚",
            "scenario_4": "æƒ…æ™¯ 4: æ·±åº¦ç†Šå¸‚"
        }
        
        # æ„å»ºæ¦‚ç‡æ‘˜è¦
        prob_summary = "\n".join([
            f"- {scenario_names[k]}: {v['probability']}%"
            for k, v in probabilities.items()
        ])
        
        analysis_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ å¯†è´§å¸å®è§‚åˆ†æå¸ˆã€‚

ã€å½“å‰å®è§‚æ•°æ®ã€‘
{json.dumps(macro_data, ensure_ascii=False, indent=2)}

ã€è§„åˆ™è¯„åˆ†ç³»ç»Ÿè®¡ç®—çš„æ¦‚ç‡ã€‘
{prob_summary}

ã€æœ€å¯èƒ½æƒ…æ™¯ã€‘
{most_likely['name']} ({most_likely['probability']}%)

è¯·åŸºäºä»¥ä¸Šæ•°æ®å’Œæ¦‚ç‡åˆ†æï¼Œç”Ÿæˆè¯¦ç»†çš„æ“ä½œå»ºè®®ã€‚

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
{{
  "ä»·æ ¼ç›®æ ‡é¢„æœŸ": "$XX,XXX - $XX,XXX",
  "æ“ä½œå»ºè®®": {{
    "ä»“ä½ç®¡ç†": "å…·ä½“å»ºè®®ï¼ˆè€ƒè™‘æœ€å¯èƒ½æƒ…æ™¯ï¼‰",
    "æ­¢æŸä½": "$XX,XXX",
    "æ­¢ç›ˆä½": "$XX,XXX æˆ– åˆ†æ‰¹æ­¢ç›ˆç­–ç•¥"
  }},
  "ç»¼åˆåˆ†æ": "è¯¦ç»†è¯´æ˜å½“å‰å¸‚åœºçŠ¶æ€ï¼Œä¸ºä»€ä¹ˆå„æƒ…æ™¯æœ‰ç›¸åº”æ¦‚ç‡ï¼Œé‡ç‚¹åˆ†ææœ€å¯èƒ½çš„æƒ…æ™¯",
  "é£é™©æç¤º": "é’ˆå¯¹å½“å‰æƒ…æ™¯çš„é£é™©è­¦å‘Š"
}}
"""
        
        try:
            ai_response = model.generate_content(analysis_prompt)
            cleaned_text = re.sub(r'```json\s*', '', ai_response.text).replace('```', '').strip()
            ai_analysis = json.loads(cleaned_text)
        except:
            ai_analysis = {
                "ä»·æ ¼ç›®æ ‡é¢„æœŸ": "æ•°æ®ä¸è¶³",
                "æ“ä½œå»ºè®®": {
                    "ä»“ä½ç®¡ç†": "å»ºè®®è§‚æœ›",
                    "æ­¢æŸä½": "å¾…å®š",
                    "æ­¢ç›ˆä½": "å¾…å®š"
                },
                "ç»¼åˆåˆ†æ": "AIåˆ†æç”Ÿæˆå¤±è´¥ï¼Œè¯·å‚è€ƒæ¦‚ç‡æ•°æ®",
                "é£é™©æç¤º": "æ•°æ®ä¸å®Œæ•´ï¼Œè°¨æ…æ“ä½œ"
            }
        
        # 5. ç»„è£…è¿”å›ç»“æœ
        return {
            "macro_data": macro_data,
            "scenario_probabilities": {
                scenario_names[k]: {
                    "probability": f"{v['probability']}%",
                    "raw_score": f"{v['raw_score']}/100",
                    "matched_factors": v['details']['matched'],
                    "unmatched_factors": v['details']['unmatched']
                }
                for k, v in probabilities.items()
            },
            "most_likely_scenario": {
                "name": most_likely['name'],
                "probability": f"{most_likely['probability']}%"
            },
            "ai_analysis": ai_analysis,
            "calculation_method": "rule_based_scoring_plus_ai"
        }
        
    except Exception as e:
        print(f"Scenario Analysis Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))